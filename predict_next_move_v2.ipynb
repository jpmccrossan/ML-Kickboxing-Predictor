{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHu1VA1sLGo7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Dropout, Bidirectional\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgLQToSg-hW8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXbh6-HrbNgS",
        "outputId": "018cc44e-e824-49c8-c03d-1c12df953d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueDg7M30NQmd",
        "outputId": "ee5d7d3a-963b-44ca-f243-edc19c914680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in left_elbow_angle: [ 38.78  20.98  38.61 ...  92.48  88.52 102.17]\n",
            "Unique values in left_knee_angle: [  4.33   6.31   6.46 ... 144.14 141.82  46.85]\n",
            "Unique values in left_shoulder_angle: [166.62 112.02 164.55 ...  73.01   5.69  81.76]\n",
            "Unique values in left_hip_angle: [  6.1    5.24   6.86 ... 118.52  51.17  37.2 ]\n",
            "Unique values in right_elbow_angle: [16.91 11.36 15.34 ... 95.08 86.8  80.85]\n",
            "Unique values in right_knee_angle: [ 6.22  8.41  5.32 ... 63.25 53.42 58.69]\n",
            "Unique values in right_shoulder_angle: [160.43  81.24 155.89 ...  76.98  71.78  62.59]\n",
            "Unique values in right_hip_angle: [12.64 16.02 11.93 ... 50.69 37.2  39.08]\n",
            "Unique values in predictions: ['[0]' '[1]' '[10]' '[2]']\n"
          ]
        }
      ],
      "source": [
        "file_path = 'output_predictions.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#Check unique values in each column\n",
        "for column in data.columns:\n",
        "    unique_values = data[column].unique()\n",
        "    print(f\"Unique values in {column}: {unique_values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ue__YOHNdFR"
      },
      "outputs": [],
      "source": [
        "moves = data.iloc[:, -1].apply(lambda x: int(x.strip('[]'))).values\n",
        "\n",
        "# Separate moves of F1 and F2\n",
        "fighter1_moves = moves[1::2]\n",
        "fighter2_moves = moves[2::2]\n",
        "\n",
        "# Ensure arrays have the same length!\n",
        "min_length = min(len(fighter1_moves), len(fighter2_moves))\n",
        "fighter1_moves = fighter1_moves[:min_length]\n",
        "fighter2_moves = fighter2_moves[:min_length]\n",
        "# Sequences n labels...\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(fighter1_moves) - 3):\n",
        "    sequences.append(fighter1_moves[i:i+3])  # Append a 3-move sequence from F1...\n",
        "    labels.append(fighter2_moves[i+3])       # Append the next move from F2...\n",
        "\n",
        "# Convert to np arrays\n",
        "sequences = np.array(sequences)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7aV2jytTdMT"
      },
      "outputs": [],
      "source": [
        "# Encode moves into integers\n",
        "label_encoder = LabelEncoder()\n",
        "sequences = label_encoder.fit_transform(sequences.ravel()).reshape(sequences.shape)\n",
        "labels = label_encoder.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01WfkHIKTmtM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=69)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "\n",
        "# KNN Predictions\n",
        "knn_train_predictions = knn.predict(X_train.reshape(X_train.shape[0], -1)).reshape(-1, 1)\n",
        "knn_test_predictions = knn.predict(X_test.reshape(X_test.shape[0], -1)).reshape(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtrBy1nbM9cQ"
      },
      "outputs": [],
      "source": [
        "# Combine KNN predictions with LSTM input\n",
        "X_train_combined = np.concatenate([X_train, knn_train_predictions], axis=1)\n",
        "X_test_combined = np.concatenate([X_test, knn_test_predictions], axis=1)\n",
        "\n",
        "# Reshape for LSTM input\n",
        "X_train_combined = X_train_combined.reshape((X_train_combined.shape[0], X_train_combined.shape[1], 1))\n",
        "X_test_combined = X_test_combined.reshape((X_test_combined.shape[0], X_test_combined.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEEKU7tmA1pk"
      },
      "outputs": [],
      "source": [
        "# Create tf dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_combined, y_train))\n",
        "\n",
        "# Calc class dis\n",
        "class_counts = np.bincount(y_train)\n",
        "class_weights = np.array([max(class_counts) / count for count in class_counts])\n",
        "\n",
        "# Assign sample weights based on the class distribution!\n",
        "def assign_sample_weights(X, y):\n",
        "    weight = tf.gather(class_weights, y)\n",
        "    return X, y, weight\n",
        "\n",
        "# Apply\n",
        "weighted_dataset = train_dataset.map(assign_sample_weights)\n",
        "\n",
        "# Separate into three components (features, labels, weights) VITAL\n",
        "def unpack(X, y, weight):\n",
        "    return (X, y), weight\n",
        "\n",
        "weighted_dataset = weighted_dataset.map(unpack)\n",
        "\n",
        "# Resample dataset, balance classes\n",
        "resampled_dataset = weighted_dataset.flat_map(\n",
        "    lambda data, weight: tf.data.Dataset.from_tensors(data).repeat(tf.cast(weight, tf.int64))\n",
        ")\n",
        "\n",
        "# Shuffle, batch prefetch\n",
        "balanced_dataset = resampled_dataset.shuffle(buffer_size=len(y_train)).batch(1024).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYhHfeSoTqHZ",
        "outputId": "eac04d31-9d94-4118-8f3b-e1a8299852e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "    226/Unknown \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.5171 - loss: 1.5670"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.5172 - loss: 1.5656 - val_accuracy: 0.6513 - val_loss: 1.2427 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - accuracy: 0.5839 - loss: 1.2024 - val_accuracy: 0.6479 - val_loss: 1.1526 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.5993 - loss: 1.0634 - val_accuracy: 0.3135 - val_loss: 1.2698 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.5999 - loss: 0.9964 - val_accuracy: 0.2639 - val_loss: 1.2525 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - accuracy: 0.6011 - loss: 0.9692 - val_accuracy: 0.2639 - val_loss: 1.2208 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - accuracy: 0.5889 - loss: 0.9728 - val_accuracy: 0.3135 - val_loss: 1.1890 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.5977 - loss: 0.9597 - val_accuracy: 0.3135 - val_loss: 1.2110 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - accuracy: 0.5837 - loss: 0.9712 - val_accuracy: 0.3135 - val_loss: 1.2255 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.5923 - loss: 0.9549 - val_accuracy: 0.3135 - val_loss: 1.1899 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.5744 - loss: 0.9767 - val_accuracy: 0.3135 - val_loss: 1.1700 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.5779 - loss: 0.9751 - val_accuracy: 0.3135 - val_loss: 1.1981 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - accuracy: 0.6025 - loss: 0.9547 - val_accuracy: 0.3135 - val_loss: 1.1757 - learning_rate: 0.0010\n",
            "796/796 - 3s - 3ms/step - accuracy: 0.6479 - loss: 1.1526\n",
            "\n",
            "Test accuracy: 0.6478862166404724\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_combined.shape[1], 1)),  # Shape (timesteps, features)!!!\n",
        "    \n",
        "    # LSTM\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(128, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(64, return_sequences=False),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Fully connected\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # Output\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0003)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with balanced batches!!!\n",
        "model.fit(balanced_dataset, epochs=100, validation_data=(X_test_combined, y_test), callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Eval\n",
        "test_loss, test_acc = model.evaluate(X_test_combined, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "model.save('kickboxing_predictor_improved_with_knn.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN7x2cUxTvLy",
        "outputId": "74689f16-bb3b-4929-fa3f-3012c77e403c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
            "Predicted next move: 10\n"
          ]
        }
      ],
      "source": [
        "# Function to predict\n",
        "def predict_next_move(moves_sequence):\n",
        "    # Clean and convert the input moves from strings to integers\n",
        "    moves_sequence = [int(x.strip('[]')) for x in moves_sequence]  # Convert strings to integers\n",
        "\n",
        "    # Transform\n",
        "    moves_sequence_transformed = label_encoder.transform(moves_sequence).reshape(1, -1)\n",
        "\n",
        "    #kNN initial prediction\n",
        "    knn_prediction = knn.predict(moves_sequence_transformed).reshape(-1, 1)\n",
        "\n",
        "    # Combine the original sequence with the KNN prediction\n",
        "    combined_sequence = np.concatenate([moves_sequence_transformed, knn_prediction], axis=1)\n",
        "\n",
        "    # Reshape,combined sequence to fit the LSTM model input\n",
        "    combined_sequence_reshaped = combined_sequence.reshape(1, combined_sequence.shape[1], 1)\n",
        "\n",
        "\n",
        "    # Make the final prediction using the LSTM model\n",
        "    predicted_move = model.predict(combined_sequence_reshaped)\n",
        "\n",
        "\n",
        "    # Convert the predicted class back to the original move label\n",
        "    predicted_move = label_encoder.inverse_transform([np.argmax(predicted_move)])\n",
        "\n",
        "    return predicted_move[0]\n",
        "\n",
        "\n",
        "example_sequence = ['[2]', '[2]', '[2]']  # Moves\n",
        "predicted_move = predict_next_move(example_sequence)\n",
        "print(f'Predicted next move: {predicted_move}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
